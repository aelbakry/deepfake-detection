{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from PIL import Image,ImageEnhance\n",
    "import tensorflow as tf\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 10\n",
    "max_df = 2\n",
    "window_size=4\n",
    "supersteps = (max_frames-window_size+1)\n",
    "\n",
    "df_train0 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_0/metadata.json')\n",
    "df_train1 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_1/metadata.json')\n",
    "df_train2 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_2/metadata.json')\n",
    "df_train3 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_3/metadata.json')\n",
    "df_train4 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_4/metadata.json')\n",
    "df_train5 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_5/metadata.json')\n",
    "\n",
    "\n",
    "df_train_all = [df_train0, df_train1, df_train2, df_train3, df_train4, df_train5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['REAL','FAKE']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "resnet = InceptionResnetV1(pretrained='vggface2', device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function to read video frames from given paths\"\"\"\n",
    "def read_img(path):\n",
    "    frames = []\n",
    "    for i in range(max_frames):\n",
    "        frames.append(cv2.cvtColor(cv2.imread(path[i]),cv2.COLOR_BGR2RGB))\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(index, df_train):\n",
    "    paths=[]\n",
    "    y=[]\n",
    "\n",
    "    df_train_values = list(df_train.columns.values)\n",
    "\n",
    "\n",
    "    for value in df_train_values:\n",
    "        image_paths=[]\n",
    "\n",
    "        try:\n",
    "            for num in range(max_frames):\n",
    "                path = '/home/aelbakry1999/images/margin_0/dfdc_train_part_' + str(index) +\"/\"+ value.replace('.mp4', '') + '/frame' + str(num) +'.jpeg'\n",
    "                image_paths.append(path)\n",
    "                if not os.path.exists(path):\n",
    "                    # print(path)\n",
    "                    raise Exception\n",
    "                \n",
    "            paths.append(image_paths)\n",
    "            y.append(LABELS.index(df_train[value]['label']))\n",
    "\n",
    "        except Exception as err:\n",
    "                # print(err)\n",
    "            pass\n",
    "\n",
    "\n",
    "    return paths, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function to embed video frames with InceptionResnetV1\"\"\"\n",
    "def embed(frames):\n",
    "    faces_embedded = []\n",
    "    tf_img = lambda i: ToTensor()(i).unsqueeze(0)\n",
    "    embeddings = lambda input: resnet(input)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for faces in tqdm(frames):\n",
    "            vid_embs = []\n",
    "            for i in range(max_frames):\n",
    "                t = tf_img(faces[i]).to(device)\n",
    "                e = embeddings(t).squeeze().cpu().tolist()\n",
    "                vid_embs.append(e)\n",
    "            faces_embedded.append(vid_embs)\n",
    "\n",
    "    return  faces_embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:00, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training paths and y values from JSON files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7239\n",
      "7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_paths=[]\n",
    "all_y=[]\n",
    "\n",
    "\"\"\"Loading all paths and y_labels in df_train_all \"\"\"\n",
    "print(\"Loading training paths and y values from JSON files\")\n",
    "for index in tqdm(range(np.shape(df_train_all)[0])):\n",
    "    path, labels = load_data(index, df_train_all[index])\n",
    "    all_paths.extend(path)\n",
    "    all_y.extend(labels)\n",
    "\n",
    "print(len(all_paths) )\n",
    "print(len(all_y) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = all_paths[:int(len(all_paths)*0.7)] \n",
    "y = all_y[:int(len(all_y)*0.7)] \n",
    "\n",
    "paths_test = all_paths[int(len(all_paths)*0.7):] \n",
    "y_test = all_y[int(len(all_y)*0.7):] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = np.array(paths)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "paths_test = np.array(paths_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=2) #convert y training to one hot encodings\n",
    "# y_test = to_categorical(y_test, num_classes=2) #convert y testing to one hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/5067 [00:00<00:19, 257.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5067/5067 [00:21<00:00, 237.17it/s]\n",
      "  1%|          | 25/2172 [00:00<00:08, 246.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2172/2172 [00:09<00:00, 239.71it/s]\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "print(\"Loading frames training\")\n",
    "for img in tqdm(paths):\n",
    "    X.append(read_img(img))\n",
    "    \n",
    "    \n",
    "X_test=[]\n",
    "print(\"Loading frames testing\")\n",
    "for img in tqdm(paths_test):\n",
    "    X_test.append(read_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(X)\n",
    "test_size = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5067, 2)\n",
      "(2172,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1108/5067 [03:23<11:41,  5.64it/s]"
     ]
    }
   ],
   "source": [
    "X_embedded = embed(X)\n",
    "\n",
    "X_test_embedded = embed(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rolled = []\n",
    "\n",
    "for i in range(len(X_embedded)):\n",
    "        rolled = window(X_embedded[i], n=window_size)\n",
    "        X_rolled.append(list(rolled))\n",
    "        \n",
    "        \n",
    "X_test_rolled = []\n",
    "\n",
    "for i in range(len(X_test_embedded)):\n",
    "        rolled = window(X_test_embedded[i], n=window_size)\n",
    "        X_test_rolled.append(list(rolled))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_rolled))\n",
    "print(np.shape(X_test_rolled))\n",
    "print(y.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rolled = np.reshape(X_rolled, (train_size, supersteps , window_size , 512))\n",
    "X_test_rolled = np.reshape(X_test_rolled, (test_size, supersteps , window_size , 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    \"\"\"Build a simple LSTM network. On the training sample\"\"\"\n",
    "    # Model.\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(LSTM(2048, return_sequences=False), input_shape=( supersteps , window_size , 512 ) ))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add((Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = lstm()\n",
    "\n",
    "optimizer = Adam(lr=1e-5*10, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_rolled, y, epochs=10, batch_size=64, shuffle=True)\n",
    "model.save_weights(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict_classes(X_test_rolled)\n",
    "\n",
    "\n",
    "print(y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions\", y_preds)\n",
    "print(\"True Labels\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_preds)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "\n",
    "\n",
    "print(\"-------------- Confusion Matrix -------------- \")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "print('True Positives: {}, True Negatives: {}, False Positives: {}, False Negatives: {}'.format(tp, tn, fp, fn))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2*(precision*recall)/ (precision+recall)\n",
    "print(\"-------------- Model Scores -------------- \")\n",
    "print('Precision: {}, Accuracy: {}, Recall: {}, F1-score: {}'.format(precision, accuracy, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('/home/aelbakry1999/Results/accuracy_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
