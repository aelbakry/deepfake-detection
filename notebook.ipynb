{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from PIL import Image,ImageEnhance\n",
    "import tensorflow as tf\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 10\n",
    "max_df = 2\n",
    "window_size= 5\n",
    "supersteps = (max_frames-window_size+1)\n",
    "\n",
    "df_train0 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_0/metadata.json')\n",
    "df_train1 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_1/metadata.json')\n",
    "df_train2 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_2/metadata.json')\n",
    "df_train3 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_3/metadata.json')\n",
    "df_train4 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_4/metadata.json')\n",
    "df_train5 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_5/metadata.json')\n",
    "df_train6 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_6/metadata.json')\n",
    "df_train7 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_7/metadata.json')\n",
    "df_train8 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_8/metadata.json')\n",
    "df_train9 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_9/metadata.json')\n",
    "df_train10 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_10/metadata.json')\n",
    "df_train11 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_11/metadata.json')\n",
    "df_train12 = pd.read_json('/home/aelbakry1999/dfdc/dfdc_train_part_12/metadata.json')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train_all = [df_train0, df_train1, df_train2, df_train3, df_train4, \n",
    "                df_train5, df_train6, df_train7, df_train8, df_train9, \n",
    "                df_train10]\n",
    "\n",
    "df_test_all = [df_train11, df_train12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['REAL','FAKE']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "resnet = InceptionResnetV1(pretrained='vggface2', device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function to read video frames from given paths\"\"\"\n",
    "def read_img(path):\n",
    "    frames = []\n",
    "    for i in range(max_frames):\n",
    "        frames.append(cv2.cvtColor(cv2.imread(path[i]),cv2.COLOR_BGR2RGB))\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(index, df_train):\n",
    "    paths=[]\n",
    "    y=[]\n",
    "\n",
    "    df_train_values = list(df_train.columns.values)\n",
    "\n",
    "\n",
    "    for value in df_train_values:\n",
    "        image_paths=[]\n",
    "\n",
    "        try:\n",
    "            for num in range(max_frames):\n",
    "                path = '/home/aelbakry1999/images/margin_0/dfdc_train_part_' + str(index) +\"/\"+ value.replace('.mp4', '') + '/frame' + str(num) +'.jpeg'\n",
    "                image_paths.append(path)\n",
    "                if not os.path.exists(path):\n",
    "                    # print(path)\n",
    "                    raise Exception\n",
    "                \n",
    "            paths.append(image_paths)\n",
    "            y.append(LABELS.index(df_train[value]['label']))\n",
    "\n",
    "        except Exception as err:\n",
    "                # print(err)\n",
    "            pass\n",
    "\n",
    "\n",
    "    return paths, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function to embed video frames with InceptionResnetV1\"\"\"\n",
    "def embed(frames):\n",
    "    faces_embedded = []\n",
    "    tf_img = lambda i: ToTensor()(i).unsqueeze(0)\n",
    "    embeddings = lambda input: resnet(input)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for faces in tqdm(frames):\n",
    "            vid_embs = []\n",
    "            for i in range(max_frames):\n",
    "                t = tf_img(faces[i]).to(device)\n",
    "                e = embeddings(t).squeeze().cpu().tolist()\n",
    "                vid_embs.append(e)\n",
    "            faces_embedded.append(vid_embs)\n",
    "\n",
    "    return  faces_embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_paths=[]\n",
    "# all_y=[]\n",
    "\n",
    "# \"\"\"Loading all paths and y_labels in df_train_all \"\"\"\n",
    "# # print(\"Loading training paths and y values from JSON files\")\n",
    "# for index in tqdm(range(np.shape(df_train_all)[0])):\n",
    "#     path, labels = load_data(index, df_train_all[index])\n",
    "#     all_paths.extend(path)\n",
    "#     all_y.extend(labels)\n",
    "\n",
    "# print(len(all_paths) )\n",
    "# print(len(all_y) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = all_paths[:int(len(all_paths)*0.8)] \n",
    "# y = all_y[:int(len(all_y)*0.8)] \n",
    "\n",
    "# paths_test = all_paths[int(len(all_paths)*0.8):] \n",
    "# y_test = all_y[int(len(all_y)*0.8):] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16129\n",
      "16129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "paths=[]\n",
    "y=[]\n",
    "\n",
    "\"\"\"Loading all paths and y_labels in df_train_all \"\"\"\n",
    "# print(\"Loading training paths and y values from JSON files\")\n",
    "for index in tqdm(range(np.shape(df_train_all)[0])):\n",
    "    path, labels = load_data(index, df_train_all[index])\n",
    "    paths.extend(path)\n",
    "    y.extend(labels)\n",
    "\n",
    "print(len(paths) )\n",
    "print(len(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055\n",
      "2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "paths_test=[]\n",
    "y_test=[]\n",
    "\n",
    "\"\"\"Loading all paths and y_labels in df_train_all \"\"\"\n",
    "# print(\"Loading training paths and y values from JSON files\")\n",
    "for index in tqdm(range(np.shape(df_test_all)[0])):\n",
    "    path, labels = load_data(index, df_train_all[index])\n",
    "    paths_test.extend(path)\n",
    "    y_test.extend(labels)\n",
    "\n",
    "print(len(paths_test) )\n",
    "print(len(y_test) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14076 fake train samples\n",
      "There are 2053 real train samples\n",
      "There are 1921 fake train samples\n",
      "There are 134 real train samples\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(y.count(1))+' fake train samples')\n",
    "print('There are '+str(y.count(0))+' real train samples')\n",
    "print('There are '+str(y_test.count(1))+' fake train samples')\n",
    "print('There are '+str(y_test.count(0))+' real train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Underbalancing training \"\"\"\n",
    "\n",
    "import random\n",
    "real=[]\n",
    "fake=[]\n",
    "for m,n in zip(paths,y):\n",
    "    if n==0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake=random.sample(fake,len(real))\n",
    "paths,y=[],[]\n",
    "for x in real:\n",
    "    paths.append(x)\n",
    "    y.append(0)\n",
    "for x in fake:\n",
    "    paths.append(x)\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Underbalancing validation/ test\"\"\"\n",
    "\n",
    "import random\n",
    "real=[]\n",
    "fake=[]\n",
    "for m,n in zip(paths_test,y_test):\n",
    "    if n==0:\n",
    "        real.append(m)\n",
    "    else:\n",
    "        fake.append(m)\n",
    "fake=random.sample(fake,len(real))\n",
    "paths_test,y_test=[],[]\n",
    "for x in real:\n",
    "    paths_test.append(x)\n",
    "    y_test.append(0)\n",
    "for x in fake:\n",
    "    paths_test.append(x)\n",
    "    y_test.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2053 fake train samples\n",
      "There are 2053 real train samples\n",
      "There are 134 fake train samples\n",
      "There are 134 real train samples\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(y.count(1))+' fake train samples')\n",
    "print('There are '+str(y.count(0))+' real train samples')\n",
    "print('There are '+str(y_test.count(1))+' fake train samples')\n",
    "print('There are '+str(y_test.count(0))+' real train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = np.array(paths)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "paths_test = np.array(paths_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=2) #convert y training to one hot encodings\n",
    "# y_test = to_categorical(y_test, num_classes=2) #convert y testing to one hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4106/4106 [00:26<00:00, 153.13it/s]\n",
      "100%|██████████| 268/268 [00:01<00:00, 162.69it/s]\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "# print(\"Loading frames training\")\n",
    "for img in tqdm(paths):\n",
    "    X.append(read_img(img))\n",
    "    \n",
    "    \n",
    "X_test=[]\n",
    "# print(\"Loading frames testing\")\n",
    "for img in tqdm(paths_test):\n",
    "    X_test.append(read_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(X)\n",
    "test_size = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4106, 2)\n",
      "(268,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2402/4106 [08:40<05:43,  4.97it/s]"
     ]
    }
   ],
   "source": [
    "X_embedded = embed(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_embedded = embed(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rolled = []\n",
    "\n",
    "for i in range(len(X_embedded)):\n",
    "        rolled = window(X_embedded[i], n=window_size)\n",
    "        X_rolled.append(list(rolled))\n",
    "        \n",
    "        \n",
    "X_test_rolled = []\n",
    "\n",
    "for i in range(len(X_test_embedded)):\n",
    "        rolled = window(X_test_embedded[i], n=window_size)\n",
    "        X_test_rolled.append(list(rolled))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_rolled))\n",
    "print(y.shape)\n",
    "\n",
    "print(np.shape(X_test_rolled))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rolled = np.reshape(X_rolled, (train_size, supersteps , window_size , 512))\n",
    "X_test_rolled = np.reshape(X_test_rolled, (test_size, supersteps , window_size , 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    \"\"\"Build a simple LSTM network. On the training sample\"\"\"\n",
    "    # Model.\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(LSTM(2048, return_sequences=False), input_shape=( supersteps , window_size , 512 ) ))\n",
    "    model.add(Dropout(0.5)) #large dropout\n",
    "    model.add(Flatten())\n",
    "    model.add((Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5)) #large dropout\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = lstm()\n",
    "\n",
    "optimizer = Adam(lr=1e-5*10, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_rolled, y, epochs=30, batch_size=supersteps*10, shuffle=True)\n",
    "model.save_weights(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict_classes(X_test_rolled)\n",
    "\n",
    "\n",
    "print(y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "print(y_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions\", y_preds)\n",
    "print(\"True Labels\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_preds)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_preds).ravel()\n",
    "\n",
    "\n",
    "print(\"-------------- Confusion Matrix -------------- \")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "print('True Positives: {}, True Negatives: {}, False Positives: {}, False Negatives: {}'.format(tp, tn, fp, fn))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2*(precision*recall)/ (precision+recall)\n",
    "print(\"-------------- Model Scores -------------- \")\n",
    "print('Precision: {}, Accuracy: {}, Recall: {}, F1-score: {}'.format(precision, accuracy, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('/home/aelbakry1999/Results/accuracy_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
